1. 创建爬虫的项目   scrapy startproject 项目的名字
                 注意：项目的名字不允许使用数字开头  也不能包含中文
2. 创建爬虫文件
                 要在spiders文件夹中去创建爬虫文件
                 cd 项目的名字\项目的名字\spiders
                 cd scrapy_baidu_091\scrapy_baidu_091\spiders

                 创建爬虫文件
                 scrapy genspider 爬虫文件的名字  要爬取网页
                 eg：scrapy genspider baidu  http://www.baidu.com
                 一般情况下不需要添加http协议  因为start_urls的值是根据allowed_domains
                 修改的  所以添加了http的话  那么start_urls就需要我们手动去修改了
3. 运行爬虫代码
                 scrapy crawl 爬虫的名字
                 eg：
                 scrapy crawl baidu

1. scrapy项目的结构
    项目名字
        项目名字
            spiders文件夹 （存储的是爬虫文件）
                init
                自定义的爬虫文件    核心功能文件  ****************
            init
            items        定义数据结构的地方 爬取的数据都包含哪些
            middleware   中间件    代理
            pipelines    管道   用来处理下载的数据
            settings     配置文件    robots协议  ua定义等

2. response的属性和方法
    response.text   获取的是响应的字符串
    response.body   获取的是二进制数据
    response.xpath  可以直接使用xpath方法来解析response中的内容
    response.extract()   提取seletor对象的data属性值
    response.extract_first() 提取的seletor列表的第一个数据